<!doctype html>
<html prefix="og: http://ogp.me/ns#">
    <head>
        <meta charset="utf-8" />
        <meta http-equiv='X-UA-Compatible' content='IE=edge;chrome=1' />
        <meta content="width=device-width" name="viewport">
        <title>Stephen Tu on Least Squares Policy Iteration | Papers We Love</title>
        <meta name="description" content="Stephen Tu on Least Squares Policy Iteration" />
        <meta name="fb:description" content="Stephen Tu on Least Squares Policy Iteration">
        <meta name="fb:image" content="http://paperswelove.org/images/papers-we-love-ogp.png">
        <meta name="fb:image:type" content="image/png">
        <meta name="fb:image:width" content="400">
        <meta name="fb:image:height" content="300">
        <meta name="og:site_name" content="Papers We Love">
        <meta name="og:description" content="Stephen Tu on Least Squares Policy Iteration">
        <meta name="og:image" content="http://paperswelove.org/images/papers-we-love-ogp.png">
        <meta name="og:image:type" content="image/png">
        <meta name="og:image:width" content="400">
        <meta name="og:image:height" content="300">
        <meta name="og:locale" content="en_us">
        <meta name="og:type" content="article">
        <meta name="og:title" content="Stephen Tu on Least Squares Policy Iteration">
        <meta name="og:url" content="http://paperswelove.org/2017/video/stephen-tu-policy-iteration/">
        <meta name="article:published_time" content="2017-09-29T00:00:00Z">
        <meta name="article:tag" content="meetup">
        <meta name="article:tag" content="video">
        <meta name="twitter:card" content="summary" />
        <meta name="twitter:site" content="@papers_we_love" />
        <meta name="twitter:title" content="Stephen Tu on Least Squares Policy Iteration | Papers We Love" />
        <meta name="twitter:description" content="Stephen Tu on Least Squares Policy Iteration" />
        <meta name="google-site-verification" content="aMC4-woz3t3pTn9EbEL4wIUkYtnYddGFNGee-sqQNb0" />
        <link href="/stylesheets/font-awesome.min.css" rel="stylesheet" /><link href="/stylesheets/screen.css" rel="stylesheet" />
        <link rel="alternate" type="application/atom+xml" title="Atom Feed" href="/feed.xml" />
        <link href="/favicon.ico" rel="icon" type="image/ico" />
        <link href="/images/favicon.ico" rel="shortcut icon" type="image/x-icon" />
        <script>
         (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
             (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
                                  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
                                  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

         ga('create', 'UA-53240153-1', 'auto');
         ga('send', 'pageview');
        </script>
    </head>
    <body id="generic" itemscope itemtype="http://schema.org/WebPage">
        <section class="nav-top">
  <div class="nav-top-img">
<a href="/">      <img alt="Papers We Love" title="Papers We Love | A community for computer science papers" src="/images/logo-top.svg" />
</a>  </div>
  <nav>
    <ul class="nav-top-list">
      <li><a href="https://github.com/papers-we-love/papers-we-love">Papers</a></li>
      <li><a href="/categories/video">Videos</a></li>
      <li><a href="/chapter">Chapters</a></li>
      <li><a href="https://github.com/papers-we-love/papers-we-love#contributing-guidelines">Submission Guidelines</a></li>
      <li><a href="https://github.com/papers-we-love/organizers">Start A Chapter</a></li>
      <li><a href="https://pwlconf.org">PWLConf</a></li>
    </ul>
  </nav>
</section>
<!--
     <section class="pwlconf-banner" role="button" aria-label="Buy tickets for PWLConf 2018" onclick="bannerClick()">
     <img class="banner-img" alt="Papers We Love Conf" title="PWLConf 2018 | St. Louis, MO - September 28th" src="/images/pwl-type-thick-web.svg" />
     <div>
     <h3>Coming again to St. Louis on September 12th, 2019</h3>
     <h4>Buy tickets here!</h4>
     </div>
     </section>
     <script>
     function bannerClick(e) {
     window.location.href="https://pwlconf.org";
     }
     </script>
-->


        <div id="main" role="main" itemprop="mainContentOfPage">
                <article class="hentry article" itemscope itemtype="http://schema.org/Article">
        <h1 itemprop="headline">Stephen Tu on Least Squares Policy Iteration</h1>
        
        <section itemprop="articleBody">
        <iframe class="video" width="560" height="315" src="https://www.youtube.com/embed/WpHPMqzufJY" frameborder="0" allowfullscreen=""></iframe>

<p></p>

<h2 id="new-york---august-31-2017">New York - August 31, 2017</h2>

<hr />

<ul>
  <li><strong>Meetup:</strong> <a href="https://www.meetup.com/papers-we-love/events/242063907/">https://www.meetup.com/papers-we-love/events/242063907/</a></li>
  <li><strong>Paper:</strong> <a href="https://users.cs.duke.edu/~parr/jmlr03.pdf">Least Squares Policy Iteration</a></li>
  <li><strong>Slides:</strong> <a href="https://speakerdeck.com/paperswelove/stephen-tu-on-least-squares-policy-iteration">Stephen Tu on Least Squares Policy Iteration</a></li>
  <li><strong>Audio:</strong> <a href="https://www.mixcloud.com/paperswelove/stephen-tu-on-least-squares-policy-iteration/">Stephen Tu on Least Squares Policy Iteration</a></li>
</ul>

<p><strong>Description</strong></p>

<p>Policy iteration is a classic dynamic programing algorithm for solving a Markov Decision Process (MDP). In policy iteration, the algorithm alternates between two steps: 1) a policy evaluation step which, given the current policy, computes the state-action value function (commonly known as the Q-function) for the policy, and 2) a policy improvement step, which uses the Q-function to greedily improve the current policy. When the number of states and actions of the MDP is finite and small, policy iteration performs well and comes with nice theoretical guarantees. However, when the state and action spaces are large (possibly continuous), policy iteration becomes intractable, and approximate methods for solving MDPs must be used.</p>

<p>Least Squares Policy Iteration (LSPI) is one method for approximately solving an MDP. The key idea here is to approximate the Q-function as a linear functional in a lifted, higher dimensional space, analogous to the idea of feature maps in supervised learning. Plugging this approximation into the Bellman equation gives a tractable linear system of equations to solve for the policy evaluation step. Furthermore, the policy improvement step remains the same as before.</p>

<p>This talk describes LSPI and some of its subtleties. One subtlety arises due to the fact that the Bellman operator is not necessarily invariant on our approximate function class, and hence an extra projection step is typically used to minimize the Bellman residual after projecting back on the function space. Furthermore, in order to build intuition for LSPI, I will also talk about what the LSPI algorithm does in the context of a well studied continuous optimal control problem known as the Linear Quadratic Regulator (LQR).</p>

<p><strong>Bio</strong></p>

<p><a href="https://people.eecs.berkeley.edu/~stephentu/">Stephen Tu</a> is a PhD student in the EECS department at UC Berkeley, studying problems in the intersection of optimization, control theory, and statistics. This summer, he is interning at the Google Brain team in NYC, which has sparked his interest in reinforcement learning.</p>

<p><strong>Audio</strong></p>

<iframe width="100%" height="60" src="https://www.mixcloud.com/widget/iframe/?hide_cover=1&amp;mini=1&amp;feed=%2Fpaperswelove%2Fstephen-tu-on-least-squares-policy-iteration%2F" frameborder="0"></iframe>

<p><strong>Slides</strong></p>

<iframe class="video" allowfullscreen="true" allowtransparency="true" frameborder="0" height="596" mozallowfullscreen="true" src="//speakerdeck.com/player/d1ca498f1955406dac8ebb85ece952ad" style="border:0; padding:0; margin:0; background:transparent;" webkitallowfullscreen="true" width="710"></iframe>

<hr />

<p style="display: flex; flex-direction: row; justify-content: center; align-items: center;">
<a href="https://www.twosigma.com/"><img src="/images/TwoSigma_RGB.jpg" alt="TwoSigma" title="TwoSigma - Platinum Sponsor of Papers We Love NYC" style="width: 200px; margin: 0 1em 0 0;" /></a> <span style="flex: 1;">The <strong>New York Chapter</strong> would like to thank <a href="https://www.twosigma.com">TwoSigma</a> for helping to make this meetup possible.</span>
</p>

<hr />

        </section>
        <footer class="article-metadata">
            <em>Tags:</em>
                <a href="/tags/meetup">meetup</a>
                <a href="/tags/video">video</a>
            <em>Category:</em>
            <a href="/categories/video">video</a>
            <em>Posted by:</em>
            Lydia Gu
        </footer>
    </article>

        </div>

        <footer class="nav-footer" itemscope itemtype="http://schema.org/Organization">
  <nav>
    <ul class="nav-top-list nav-footer-list">
      <li><a href="/">Home</a></li>
      <li><a href="https://github.com/papers-we-love/papers-we-love">Papers</a></li>
      <li><a href="/chapter">Chapters</a></li>
      <li><a href="https://github.com/papers-we-love/papers-we-love#contributing-guidelines">Submission Guidelines</a></li>
    </ul>
  </nav>
  <h3>&copy; 2019 <span itemprop="name">Papers We Love<sup>SM</sup></span>, all rights reserved | Watch the videos from <a href="http://pwlconf.org">PWLConf!</a>
</footer>

    </body>
</html>
<!--
All content and design is Copyright (c) 2019
Papers We Love, all rights reserved
-->
